{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last lesson\n",
    "\n",
    "- A wrapper for `CartPole-v0` that lets us choose the initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitMod(gym.Wrapper):\n",
    "    def __init__(self, env, initial_state):\n",
    "        super().__init__(env)\n",
    "        self.initial_state = initial_state\n",
    "        \n",
    "    def reset(self):\n",
    "        observation = self.env.reset()\n",
    "        self.unwrapped.state = self.initial_state\n",
    "        return self.unwrapped.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization choice: pole to the right \n",
    "\n",
    "1. Cart position = 0\n",
    "2. Cart velocity = 0.01\n",
    "3. Pole angle = 0.15\n",
    "4. The pole tip velocity = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pole_right_init_cartpole_env = InitMod(env=gym.make(\"CartPole-v0\"), initial_state=np.array([0, 0.01, 0.15, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.01 0.15 0.  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = pole_right_init_cartpole_env.reset()\n",
    "print(observation)\n",
    "pole_right_init_cartpole_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pole_right_init_cartpole_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does changing the initial state have an impact on the total rewards?\n",
    "- For the default initialization, we get an average total reward of around 22.5 when following the random policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_total_rewards_per_episode(env, policy_sampling_function, num_episodes):\n",
    "    total_rewards = 0\n",
    "    for num_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        while True:\n",
    "            if num_episode == 0:\n",
    "                env.render()\n",
    "            action = policy_sampling_function(observation)\n",
    "            observation, reward, done, _ = env.step(action)\n",
    "            total_rewards += reward\n",
    "            if done:\n",
    "                break\n",
    "    env.close()\n",
    "    print(f\"Average total rewards per episode for {num_episodes} episodes is {total_rewards / num_episodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling function for the random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling function for the random policy\n",
    "import random \n",
    "\n",
    "def get_action_random_policy(observation):\n",
    "    if random.random() < 0.5:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total rewards per episode for 1000 episodes is 16.746\n"
     ]
    }
   ],
   "source": [
    "get_average_total_rewards_per_episode(pole_right_init_cartpole_env, get_action_random_policy, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization choice: non zero pole velocity\n",
    "\n",
    "1. Cart position = 0\n",
    "2. Cart velocity = 0.01\n",
    "3. Pole angle = 0.\n",
    "4. The pole tip velocity = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "non_zero_pole_velocity_init_cartpole_env = InitMod(env=gym.make(\"CartPole-v0\"), initial_state=np.array([0, 0.01, 0., 2.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average reward for the \"non zero pole velocity\" initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total rewards per episode for 1000 episodes is 6.102\n"
     ]
    }
   ],
   "source": [
    "get_average_total_rewards_per_episode(non_zero_pole_velocity_init_cartpole_env, get_action_random_policy, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The expected total rewards per episode, while following a policy, depends on the starting state!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value of a state, given a policy: The expected total rewards per episode you get starting from the state if you follow the given policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| State | State description | Policy | Value function |\n",
    "| --- | --- | --- | --- |\n",
    "| `[0, 0.01, 0.15, 0]` | Pole angled to the right | random | 16 |\n",
    "| `[0., 0.01, 0., 2.0]` | Non zero pole tip velocity | random | 6 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling function for the epsilon pole direction policy with $\\epsilon=0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_action_epsilon_pole_direction_policy(observation):\n",
    "    if random.random() < 0.9:\n",
    "        return get_action_random_policy(observation)\n",
    "    if observation[2] > 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average reward for \"pole right\" init and epsilon pole direction policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total rewards per episode for 1000 episodes is 19.728\n"
     ]
    }
   ],
   "source": [
    "get_average_total_rewards_per_episode(pole_right_init_cartpole_env, get_action_epsilon_pole_direction_policy, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average reward for \"non zero pole velocity\" init and epsilon pole direction policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total rewards per episode for 1000 episodes is 6.346\n"
     ]
    }
   ],
   "source": [
    "get_average_total_rewards_per_episode(non_zero_pole_velocity_init_cartpole_env, get_action_epsilon_pole_direction_policy, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| State | State description | Policy | Value function |\n",
    "| --- | --- | --- | --- |\n",
    "| `[0, 0.01, 0.15, 0]` | Pole angled to the right | random | 16 |\n",
    "| `[0, 0.01, 0.15, 0]` | Pole angled to the right | epsilon pole direction | 19 |\n",
    "| `[0., 0.01, 0., 2.0]` | Non zero pole tip velocity | random | 6 |\n",
    "| `[0., 0.01, 0., 2.0]` | Non zero pole tip velocity | epsilon pole direction | 6 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
